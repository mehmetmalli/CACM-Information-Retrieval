{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "from num2words import num2words\n",
    "from collections import Counter\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# read all data file\n",
    "filename = \"../files/cacm.all_processed\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    linesArr = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# remove newlines\n",
    "for i in range(len(linesArr)):\n",
    "    linesArr[i] = linesArr[i].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create array for each document\n",
    "documentsArr = []\n",
    "document = []\n",
    "for i in range(len(linesArr)):\n",
    "    line = linesArr[i]\n",
    "    if(line == \"SPLITTER_TEXT\"):\n",
    "        if(i != 0):\n",
    "            documentsArr.append(document)    \n",
    "        document = []\n",
    "    else:\n",
    "        document.append(line)\n",
    "        \n",
    "if(len(documentsArr) == 3204):\n",
    "    print(\"All documents have been successfully seperated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "documents = {}\n",
    "\n",
    "for document in documentsArr:\n",
    "    docObj = {}\n",
    "    \n",
    "    docID = int(document[0].split(\" \")[1])\n",
    "    \n",
    "    title = \"\"\n",
    "    \n",
    "    indexofT = document.index(\".T\")\n",
    "    indexofB = document.index(\".B\")\n",
    "    \n",
    "    if \".W\" in document:\n",
    "        abstract = \"\"\n",
    "        indexofW = document.index(\".W\")\n",
    "        for i in range(indexofT + 1, indexofW):\n",
    "            title += \" \" + document[i]\n",
    "        for i in range(indexofW + 1, indexofB):\n",
    "            abstract += \" \" + document[i]\n",
    "        docObj[\"abstract\"] = abstract[1:]\n",
    "        \n",
    "    else:\n",
    "        for i in range(indexofT + 1, indexofB):\n",
    "            title += \" \" + document[i]\n",
    "            \n",
    "    docObj[\"title\"] = title[1:]        \n",
    "            \n",
    "    if \".A\" in document:\n",
    "        authors = \"\"\n",
    "        indexofA = document.index(\".A\")\n",
    "        \n",
    "        if \".K\" in document:\n",
    "            indexofK = document.index(\".K\")\n",
    "            for i in range(indexofA + 1, indexofK):\n",
    "                authors += \" \" + document[i]\n",
    "                \n",
    "        else:\n",
    "            for i in range(indexofA + 1, len(document)):\n",
    "                authors += \" \" + document[i]\n",
    "            \n",
    "        docObj[\"authors\"] = authors[1:]\n",
    "        \n",
    "    if \".K\" in document:\n",
    "        keywords = \"\"\n",
    "        indexofK = document.index(\".K\")\n",
    "        for i in range(indexofK + 1, len(document)):\n",
    "            keywords += \" \" + document[i]\n",
    "        docObj[\"keywords\"] = keywords[1:]\n",
    "    \n",
    "\n",
    "    \n",
    "    documents[docID] = docObj\n",
    "\n",
    "if(len(documents) == 3204):\n",
    "    print(\"All documents have been successfully parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# read queries file\n",
    "filename = \"../files/query.text\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    linesArr = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# remove newlines\n",
    "for i in range(len(linesArr)):\n",
    "    linesArr[i] = linesArr[i].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create array for each query\n",
    "queriesArr = []\n",
    "query = []\n",
    "for i in range(len(linesArr)):\n",
    "    line = linesArr[i]\n",
    "    if(line == \" \" or line == \"\"):\n",
    "        if(i != 0):\n",
    "            queriesArr.append(query)    \n",
    "        query = []\n",
    "    else:\n",
    "        query.append(line)\n",
    "        \n",
    "if(len(queriesArr) == 64):\n",
    "    print(\"All queries have been successfully seperated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# additional parsing and organization of queries\n",
    "queries = {}\n",
    "\n",
    "for query in queriesArr:\n",
    "    queryText = \"\"\n",
    "    queryID = int(query[0].split(\" \")[1])\n",
    "    indexofW = query.index(\".W\")\n",
    "    if \".A\" in query:\n",
    "        indexofA = query.index(\".A\")\n",
    "        for i in range(indexofW + 1, indexofA):\n",
    "            queryText += \" \" + query[i]\n",
    "    else:\n",
    "        indexofN = query.index(\".N\")\n",
    "        for i in range(indexofW + 1, indexofN):\n",
    "            queryText += \" \" + query[i]\n",
    "    queries[queryID] = queryText[2:]\n",
    "    \n",
    "if(len(queries) == 64):\n",
    "    print(\"All queries have been successfully parsed.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# read query relations file\n",
    "filename = \"../files/qrels.text\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    linesArr = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create dictionary to store query relations\n",
    "queryRelations = {}\n",
    "\n",
    "for line in linesArr:\n",
    "    line = line.split(\" \")\n",
    "    queryID = int(line[0])\n",
    "    docID = int(line[1])\n",
    "    \n",
    "    if queryID in queryRelations:\n",
    "        temp = queryRelations[queryID]\n",
    "        temp.append(docID)\n",
    "        queryRelations[queryID] = temp\n",
    "    else:\n",
    "        queryRelations[queryID] = [docID]\n",
    "\n",
    "if(len(queryRelations) == 52):\n",
    "    print(\"All query relations have been successfully parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# read query relations file\n",
    "filename = \"../files/common_words\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    common_words = file.readlines()\n",
    "\n",
    "if len(common_words) == 429:\n",
    "    print(\"All common words have been successfully parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define sub-preprocessing functions\n",
    "def convert_to_lowercase(text):\n",
    "    return np.array_str(np.char.lower(text))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;,<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in symbols:\n",
    "        text = np.array_str(np.char.replace(text, i, ' '))\n",
    "    return text  \n",
    "\n",
    "def remove_apostrophe(text):\n",
    "    return np.array_str(np.char.replace(text, \"'\", \"\"))\n",
    "\n",
    "def remove_single_characters(text):\n",
    "    new_text = \"\"\n",
    "    words = text.split()\n",
    "    for w in words:\n",
    "        if len(w) > 1:\n",
    "           new_text += \" \" + w\n",
    "    if len(new_text) > 0 and new_text[0] == \" \":\n",
    "        new_text = new_text[1:]\n",
    "        \n",
    "    return new_text\n",
    "\n",
    "def stem_words(text):\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    new_text = \"\"\n",
    "    words = text.split()\n",
    "    for w in words:\n",
    "        w = stemmer.stem(w) \n",
    "        new_text += \" \" + w\n",
    "        \n",
    "    if new_text[0] == \" \":\n",
    "        new_text = new_text[1:]\n",
    "        \n",
    "    return new_text\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    new_text = \"\"\n",
    "    words = text.split()\n",
    "    for w in words:\n",
    "        w = lemmatizer.lemmatize(w) \n",
    "        new_text += \" \" + w\n",
    "        \n",
    "    if len(new_text) > 0 and new_text[0] == \" \":\n",
    "        new_text = new_text[1:]\n",
    "        \n",
    "    return new_text\n",
    "\n",
    "def remove_stopwords(text, choice):\n",
    "    stopword_list = []\n",
    "    if choice == \"own\":\n",
    "        stopword_list = common_words\n",
    "    elif choice == \"nltk\":\n",
    "        stopword_list = nltk.corpus.stopwords.words(\"english\")\n",
    "    else:\n",
    "        print(\"Choose 'own' or 'nltk'.\")\n",
    "        return text\n",
    "        \n",
    "    new_text = \"\"\n",
    "    words = text.split()\n",
    "    for w in words:\n",
    "        if w not in stopword_list:\n",
    "           new_text += \" \" + w\n",
    "    if len(new_text) > 0 and new_text[0] == \" \":\n",
    "        new_text = new_text[1:]\n",
    "        \n",
    "    return new_text\n",
    "\n",
    "\n",
    "\n",
    "def convert_numbers(data):\n",
    "    tokens = nltk.tokenize.word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    \n",
    "    new_text = np.array_str(np.char.replace(new_text, \"-\", \" \"))\n",
    "                            \n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# main preprocessing function\n",
    "def preprocess(text):\n",
    "    text = convert_to_lowercase(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_apostrophe(text)\n",
    "    text = remove_stopwords(text, \"nltk\")\n",
    "    text = convert_numbers(text)\n",
    "    text = lemmatize_words(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = convert_numbers(text)\n",
    "    text = lemmatize_words(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stopwords(text, \"nltk\")\n",
    "    text = remove_single_characters(text)\n",
    "    \n",
    "    #text = remove_stopwords(text, \"own\")\n",
    "    #text = stem_words(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "processed_title = {}\n",
    "processed_abstract = {}\n",
    "processed_keywords = {}\n",
    "processed_authors = {}\n",
    "\n",
    "\n",
    "for i in range(1, len(documents)+1):\n",
    "    doc = documents.get(i)\n",
    "    title = doc[\"title\"]\n",
    "    abstract = \"\"\n",
    "    authors = \"\"\n",
    "    keywords = \"\"\n",
    "    \n",
    "    if \"abstract\" in doc:\n",
    "        abstract = doc[\"abstract\"]   \n",
    "    if \"keywords\" in doc:\n",
    "        keywords = doc[\"keywords\"]  \n",
    "    if \"authors\" in doc:\n",
    "        authors = doc[\"authors\"]\n",
    "    \n",
    "    processed_title[i] = nltk.tokenize.word_tokenize(preprocess(title))\n",
    "    processed_abstract[i] = nltk.tokenize.word_tokenize(preprocess(abstract))\n",
    "    processed_keywords[i] = nltk.tokenize.word_tokenize(preprocess(keywords))\n",
    "    processed_authors[i] = nltk.tokenize.word_tokenize(preprocess(authors))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "DF = {}\n",
    "\n",
    "for i in range(1, len(processed_title) + 1):\n",
    "    \n",
    "    tokens = processed_title[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "\n",
    "    tokens = processed_abstract[i]\n",
    "    \n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "        tokens = processed_keywords[i]\n",
    "        \n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "            \n",
    "        tokens = processed_authors[i]\n",
    "        \n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "            \n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "total_vocab_size = len(DF)\n",
    "\n",
    "total_vocab = [x for x in DF]\n",
    "\n",
    "N = len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "doc = 1\n",
    "\n",
    "tf_idf_title = {}\n",
    "\n",
    "for i in range(1, N + 1):\n",
    "    \n",
    "    tokens = processed_title[i]\n",
    "    \n",
    "    counter = Counter(tokens + processed_abstract[i] + processed_keywords[i] + processed_authors[i])\n",
    "    words_count = len(tokens + processed_abstract[i] + processed_keywords[i] + processed_authors[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf_title[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF for Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "doc = 1\n",
    "\n",
    "tf_idf_abstract = {}\n",
    "\n",
    "for i in range(1, N + 1):\n",
    "    \n",
    "    tokens = processed_abstract[i]\n",
    "    \n",
    "    counter = Counter(tokens + processed_title[i] + processed_keywords[i] + processed_authors[i])\n",
    "    words_count = len(tokens + processed_title[i] + processed_keywords[i] + processed_authors[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf_abstract[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF for Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "doc = 1\n",
    "\n",
    "tf_idf_keywords = {}\n",
    "\n",
    "for i in range(1, N + 1):\n",
    "    \n",
    "    tokens = processed_keywords[i]\n",
    "    \n",
    "    counter = Counter(tokens + processed_title[i] + processed_abstract[i] + processed_authors[i])\n",
    "    words_count = len(tokens + processed_title[i] + processed_abstract[i] + processed_authors[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf_keywords[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF for Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "doc = 1\n",
    "\n",
    "tf_idf_authors = {}\n",
    "\n",
    "for i in range(1, N + 1):\n",
    "    \n",
    "    tokens = processed_authors[i]\n",
    "    \n",
    "    counter = Counter(tokens + processed_title[i] + processed_abstract[i] + processed_keywords[i])\n",
    "    words_count = len(tokens + processed_title[i] + processed_abstract[i] + processed_keywords[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf_authors[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in tf_idf_title:\n",
    "    tf_idf_title[i] *= 0.5\n",
    "    \n",
    "for i in tf_idf_abstract:\n",
    "    tf_idf_title[i] = tf_idf_abstract[i]\n",
    "    \n",
    "for i in tf_idf_keywords:\n",
    "    tf_idf_title[i] = tf_idf_keywords[i]\n",
    "\n",
    "for i in tf_idf_authors:\n",
    "    tf_idf_title[i] = tf_idf_authors[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def average_precision(predictions, actual):\n",
    "    counter = 0\n",
    "    precisions = []\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "        if pred in actual:\n",
    "            counter += 1\n",
    "            precisions.append(counter/(i+1))\n",
    "            \n",
    "    if counter == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean(precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_qrels(filename, queryNum, docs):\n",
    "    \n",
    "    f = open(\"./output/\" + filename, \"a\")\n",
    "    for doc in docs:\n",
    "        queryNumStr = str(queryNum)\n",
    "        docStr = str(doc)\n",
    "        \n",
    "        while len(queryNumStr) < 2:\n",
    "            queryNumStr = \"0\" + queryNumStr\n",
    "            \n",
    "        while len(docStr) < 4:\n",
    "            docStr = \"0\" + docStr    \n",
    "        \n",
    "        line = \"\" + queryNumStr + \" \" + docStr + \"\\n\"\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def matching_score(k, queryNum):\n",
    "    query = queries[queryNum]\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = nltk.tokenize.word_tokenize(str(preprocessed_query))\n",
    "    match_counter = 0\n",
    "    query_weights = {}\n",
    "\n",
    "    for key in tf_idf_title:\n",
    "        \n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf_title[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf_title[key]\n",
    "    \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for i in query_weights[:k]:\n",
    "        l.append(i[0])\n",
    "    \n",
    "    #create_qrels(\"matching_score_qrels.text\", queryNum, l)\n",
    "    \n",
    "    show = False\n",
    "    for item in l:\n",
    "        if queryNum in queryRelations and item in queryRelations[queryNum]:\n",
    "            show = True\n",
    "            match_counter += 1\n",
    "            \n",
    "            \n",
    "    if queryNum in queryRelations:\n",
    "        recall = round(match_counter/len(queryRelations[queryNum]), 2)*100\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    #print(\"Q:\", queryNum, \"Precision:\", round((match_counter/k), 2)*100, \"%\" , \"Recall:\", recall)\n",
    "    \n",
    "    if queryNum in queryRelations:\n",
    "        avg_prec = average_precision(l, queryRelations[queryNum])\n",
    "    else:\n",
    "        avg_prec = 0\n",
    "        \n",
    "    print(\"Q:\", queryNum, \"Matching Score Average Precision:\", format(avg_prec*100, \".2f\"), \"%\", \"Recall:\", format(recall, \".2f\"), \"%\")\n",
    "    \n",
    "    if show:\n",
    "        #print(\"Query:\", query)\n",
    "        #print(\"Predictions:\", out)\n",
    "        #print(\"Actual:\", queryRelations[queryNum])\n",
    "        return avg_prec, 1\n",
    "    else:\n",
    "        return avg_prec, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 1 Matching Score Average Precision: 10.99 % Recall: 40.00 %\n",
      "Q: 2 Matching Score Average Precision: 12.50 % Recall: 33.00 %\n",
      "Q: 3 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 4 Matching Score Average Precision: 26.19 % Recall: 25.00 %\n",
      "Q: 5 Matching Score Average Precision: 23.32 % Recall: 50.00 %\n",
      "Q: 6 Matching Score Average Precision: 10.10 % Recall: 67.00 %\n",
      "Q: 7 Matching Score Average Precision: 58.43 % Recall: 25.00 %\n",
      "Q: 8 Matching Score Average Precision: 10.00 % Recall: 33.00 %\n",
      "Q: 9 Matching Score Average Precision: 26.85 % Recall: 33.00 %\n",
      "Q: 10 Matching Score Average Precision: 49.44 % Recall: 23.00 %\n",
      "Q: 11 Matching Score Average Precision: 52.01 % Recall: 42.00 %\n",
      "Q: 12 Matching Score Average Precision: 52.92 % Recall: 60.00 %\n",
      "Q: 13 Matching Score Average Precision: 38.84 % Recall: 45.00 %\n",
      "Q: 14 Matching Score Average Precision: 83.33 % Recall: 5.00 %\n",
      "Q: 15 Matching Score Average Precision: 30.28 % Recall: 30.00 %\n",
      "Q: 16 Matching Score Average Precision: 33.66 % Recall: 18.00 %\n",
      "Q: 17 Matching Score Average Precision: 16.24 % Recall: 19.00 %\n",
      "Q: 18 Matching Score Average Precision: 9.17 % Recall: 18.00 %\n",
      "Q: 19 Matching Score Average Precision: 51.09 % Recall: 73.00 %\n",
      "Q: 20 Matching Score Average Precision: 5.00 % Recall: 33.00 %\n",
      "Q: 21 Matching Score Average Precision: 26.36 % Recall: 36.00 %\n",
      "Q: 22 Matching Score Average Precision: 76.96 % Recall: 53.00 %\n",
      "Q: 23 Matching Score Average Precision: 50.00 % Recall: 100.00 %\n",
      "Q: 24 Matching Score Average Precision: 66.67 % Recall: 15.00 %\n",
      "Q: 25 Matching Score Average Precision: 67.73 % Recall: 18.00 %\n",
      "Q: 26 Matching Score Average Precision: 29.04 % Recall: 17.00 %\n",
      "Q: 27 Matching Score Average Precision: 42.01 % Recall: 31.00 %\n",
      "Q: 28 Matching Score Average Precision: 68.45 % Recall: 80.00 %\n",
      "Q: 29 Matching Score Average Precision: 77.18 % Recall: 37.00 %\n",
      "Q: 30 Matching Score Average Precision: 60.00 % Recall: 50.00 %\n",
      "Q: 31 Matching Score Average Precision: 20.00 % Recall: 50.00 %\n",
      "Q: 32 Matching Score Average Precision: 20.00 % Recall: 33.00 %\n",
      "Q: 33 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 34 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 35 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 36 Matching Score Average Precision: 37.46 % Recall: 25.00 %\n",
      "Q: 37 Matching Score Average Precision: 26.67 % Recall: 17.00 %\n",
      "Q: 38 Matching Score Average Precision: 68.88 % Recall: 38.00 %\n",
      "Q: 39 Matching Score Average Precision: 75.42 % Recall: 33.00 %\n",
      "Q: 40 Matching Score Average Precision: 22.47 % Recall: 40.00 %\n",
      "Q: 41 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 42 Matching Score Average Precision: 27.78 % Recall: 14.00 %\n",
      "Q: 43 Matching Score Average Precision: 64.65 % Recall: 7.00 %\n",
      "Q: 44 Matching Score Average Precision: 10.99 % Recall: 12.00 %\n",
      "Q: 45 Matching Score Average Precision: 31.23 % Recall: 27.00 %\n",
      "Q: 46 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 47 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 48 Matching Score Average Precision: 20.65 % Recall: 42.00 %\n",
      "Q: 49 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 50 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 51 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 52 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 53 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 54 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 55 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 56 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 57 Matching Score Average Precision: 11.11 % Recall: 100.00 %\n",
      "Q: 58 Matching Score Average Precision: 32.93 % Recall: 17.00 %\n",
      "Q: 59 Matching Score Average Precision: 57.24 % Recall: 16.00 %\n",
      "Q: 60 Matching Score Average Precision: 27.58 % Recall: 15.00 %\n",
      "Q: 61 Matching Score Average Precision: 78.60 % Recall: 35.00 %\n",
      "Q: 62 Matching Score Average Precision: 7.69 % Recall: 12.00 %\n",
      "Q: 63 Matching Score Average Precision: 35.37 % Recall: 42.00 %\n",
      "Q: 64 Matching Score Average Precision: 0.00 % Recall: 0.00 %\n",
      "Matching score MAP:  28.999999999999996 %\n",
      "Matching score MAP(without empty queries):  35.0 %\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "counter = 0\n",
    "avg_precisions = []\n",
    "for n in queries:\n",
    "    avg_prec, cnt = matching_score(k, n)\n",
    "    counter += cnt\n",
    "    avg_precisions.append(avg_prec)\n",
    "    \n",
    "mean_avg_precision = np.mean(avg_precisions)    \n",
    "\n",
    "#print(round((counter / len(queryRelations)) * 100, 1), \"%\")\n",
    "print(\"Matching score MAP: \", round(mean_avg_precision, 2)*100, \"%\")\n",
    "print(\"Matching score MAP(without empty queries): \", round((mean_avg_precision*64)/52, 2)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim\n",
    "\n",
    "D = np.zeros((N, total_vocab_size))\n",
    "for i in tf_idf_title:\n",
    "    try:\n",
    "        ind = total_vocab.index(i[1])\n",
    "        D[i[0]][ind] = tf_idf_title[i]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "def gen_vector(tokens):\n",
    "\n",
    "    Q = np.zeros((len(total_vocab)))\n",
    "    \n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    query_weights = {}\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = math.log((N+1)/(df+1))\n",
    "\n",
    "        try:\n",
    "            ind = total_vocab.index(token)\n",
    "            Q[ind] = tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    return Q\n",
    "\n",
    "\n",
    "def cosine_similarity(k, queryNum):\n",
    "    query = queries[queryNum]\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = nltk.tokenize.word_tokenize(str(preprocessed_query))\n",
    "    match_counter = 0\n",
    "    \n",
    "    d_cosines = []\n",
    "    \n",
    "    query_vector = gen_vector(tokens)\n",
    "    \n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "        \n",
    "    out = np.array(d_cosines).argsort()[-k-1:][::-1]\n",
    "    \n",
    "    out = np.delete(out, 0)\n",
    "    \n",
    "    #create_qrels(\"cosine_sim_qrels.text\", queryNum, out)\n",
    "    \n",
    "    show = False\n",
    "    for item in out:\n",
    "        if queryNum in queryRelations and item in queryRelations[queryNum]:\n",
    "            show = True\n",
    "            match_counter += 1\n",
    "            \n",
    "    if queryNum in queryRelations:\n",
    "        recall = round(match_counter/len(queryRelations[queryNum]), 2)*100\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    #print(\"Q:\", queryNum, \"Precision:\", round((match_counter/k), 2)*100, \"%\" , \"Recall:\", recall)\n",
    "    \n",
    "    if queryNum in queryRelations:\n",
    "        avg_prec = average_precision(out, queryRelations[queryNum])\n",
    "    else:\n",
    "        avg_prec = 0\n",
    "        \n",
    "    print(\"Q:\", queryNum, \"Cosine Similarity Average Precision:\", format(avg_prec*100, \".2f\"), \"%\", \"Recall:\", format(recall, \".2f\"), \"%\")\n",
    "    \n",
    "    if show:\n",
    "        #print(\"Query:\", query)\n",
    "        #print(\"Predictions:\", out)\n",
    "        #print(\"Actual:\", queryRelations[queryNum])\n",
    "        return avg_prec, 1\n",
    "    else:\n",
    "        return avg_prec, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blackcherry/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 1 Cosine Similarity Average Precision: 19.15 % Recall: 60.00 %\n",
      "Q: 2 Cosine Similarity Average Precision: 33.54 % Recall: 100.00 %\n",
      "Q: 3 Cosine Similarity Average Precision: 11.11 % Recall: 17.00 %\n",
      "Q: 4 Cosine Similarity Average Precision: 56.67 % Recall: 25.00 %\n",
      "Q: 5 Cosine Similarity Average Precision: 20.77 % Recall: 50.00 %\n",
      "Q: 6 Cosine Similarity Average Precision: 44.77 % Recall: 100.00 %\n",
      "Q: 7 Cosine Similarity Average Precision: 69.76 % Recall: 29.00 %\n",
      "Q: 8 Cosine Similarity Average Precision: 14.29 % Recall: 33.00 %\n",
      "Q: 9 Cosine Similarity Average Precision: 18.80 % Recall: 33.00 %\n",
      "Q: 10 Cosine Similarity Average Precision: 90.60 % Recall: 46.00 %\n",
      "Q: 11 Cosine Similarity Average Precision: 70.70 % Recall: 47.00 %\n",
      "Q: 12 Cosine Similarity Average Precision: 74.36 % Recall: 60.00 %\n",
      "Q: 13 Cosine Similarity Average Precision: 76.56 % Recall: 45.00 %\n",
      "Q: 14 Cosine Similarity Average Precision: 48.49 % Recall: 11.00 %\n",
      "Q: 15 Cosine Similarity Average Precision: 27.22 % Recall: 40.00 %\n",
      "Q: 16 Cosine Similarity Average Precision: 48.12 % Recall: 18.00 %\n",
      "Q: 17 Cosine Similarity Average Precision: 30.62 % Recall: 25.00 %\n",
      "Q: 18 Cosine Similarity Average Precision: 55.26 % Recall: 18.00 %\n",
      "Q: 19 Cosine Similarity Average Precision: 50.27 % Recall: 73.00 %\n",
      "Q: 20 Cosine Similarity Average Precision: 20.13 % Recall: 100.00 %\n",
      "Q: 21 Cosine Similarity Average Precision: 20.24 % Recall: 27.00 %\n",
      "Q: 22 Cosine Similarity Average Precision: 92.55 % Recall: 53.00 %\n",
      "Q: 23 Cosine Similarity Average Precision: 75.00 % Recall: 100.00 %\n",
      "Q: 24 Cosine Similarity Average Precision: 70.00 % Recall: 15.00 %\n",
      "Q: 25 Cosine Similarity Average Precision: 76.29 % Recall: 14.00 %\n",
      "Q: 26 Cosine Similarity Average Precision: 26.37 % Recall: 17.00 %\n",
      "Q: 27 Cosine Similarity Average Precision: 64.48 % Recall: 31.00 %\n",
      "Q: 28 Cosine Similarity Average Precision: 73.33 % Recall: 80.00 %\n",
      "Q: 29 Cosine Similarity Average Precision: 94.87 % Recall: 68.00 %\n",
      "Q: 30 Cosine Similarity Average Precision: 83.33 % Recall: 50.00 %\n",
      "Q: 31 Cosine Similarity Average Precision: 66.67 % Recall: 100.00 %\n",
      "Q: 32 Cosine Similarity Average Precision: 58.33 % Recall: 67.00 %\n",
      "Q: 33 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 34 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 35 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 36 Cosine Similarity Average Precision: 60.99 % Recall: 35.00 %\n",
      "Q: 37 Cosine Similarity Average Precision: 44.77 % Recall: 25.00 %\n",
      "Q: 38 Cosine Similarity Average Precision: 65.32 % Recall: 50.00 %\n",
      "Q: 39 Cosine Similarity Average Precision: 53.00 % Recall: 42.00 %\n",
      "Q: 40 Cosine Similarity Average Precision: 54.08 % Recall: 50.00 %\n",
      "Q: 41 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 42 Cosine Similarity Average Precision: 21.13 % Recall: 19.00 %\n",
      "Q: 43 Cosine Similarity Average Precision: 35.06 % Recall: 17.00 %\n",
      "Q: 44 Cosine Similarity Average Precision: 71.93 % Recall: 18.00 %\n",
      "Q: 45 Cosine Similarity Average Precision: 62.00 % Recall: 35.00 %\n",
      "Q: 46 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 47 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 48 Cosine Similarity Average Precision: 24.36 % Recall: 17.00 %\n",
      "Q: 49 Cosine Similarity Average Precision: 20.06 % Recall: 50.00 %\n",
      "Q: 50 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 51 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 52 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 53 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 54 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 55 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 56 Cosine Similarity Average Precision: 0.00 % Recall: 0.00 %\n",
      "Q: 57 Cosine Similarity Average Precision: 50.00 % Recall: 100.00 %\n",
      "Q: 58 Cosine Similarity Average Precision: 72.75 % Recall: 27.00 %\n",
      "Q: 59 Cosine Similarity Average Precision: 70.25 % Recall: 26.00 %\n",
      "Q: 60 Cosine Similarity Average Precision: 69.30 % Recall: 44.00 %\n",
      "Q: 61 Cosine Similarity Average Precision: 75.88 % Recall: 39.00 %\n",
      "Q: 62 Cosine Similarity Average Precision: 6.25 % Recall: 12.00 %\n",
      "Q: 63 Cosine Similarity Average Precision: 37.73 % Recall: 58.00 %\n",
      "Q: 64 Cosine Similarity Average Precision: 100.00 % Recall: 100.00 %\n",
      "Cosine similarity MAP:  42.0 %\n",
      "Cosine similarity MAP(without empty queries):  51.0 %\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "counter = 0\n",
    "avg_precisions = []\n",
    "for n in queries:\n",
    "    avg_prec, cnt = cosine_similarity(k, n)\n",
    "    counter += cnt\n",
    "    avg_precisions.append(avg_prec)\n",
    "    \n",
    "mean_avg_precision = np.mean(avg_precisions)    \n",
    "\n",
    "#print(round((counter / len(queryRelations)) * 100, 1), \"%\")\n",
    "print(\"Cosine similarity MAP: \", round(mean_avg_precision, 2)*100, \"%\")\n",
    "print(\"Cosine similarity MAP(without empty queries): \", round((mean_avg_precision*64)/52, 2)*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
